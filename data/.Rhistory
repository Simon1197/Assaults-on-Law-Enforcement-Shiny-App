theme_bw()+
labs(x = "Votes", title = "IMDB Votes per Top 100 Foreign Films \n by Country")+
theme(axis.title.y = element_blank()) +
scale_x_continuous(trans='log10')
ggplot(data = datadf2) +
geom_boxplot(mapping = aes(x = votes, y = order(country, votes))) +
theme_bw()+
labs(x = "Votes", title = "IMDB Votes per Top 100 Foreign Films \n by Country")+
theme(axis.title.y = element_blank()) +
scale_x_continuous(trans='log10')
ggplot(data = datadf2) +
geom_boxplot(mapping = aes(x = votes, y = reorder(country, votes))) +
theme_bw()+
labs(x = "Votes", title = "IMDB Votes per Top 100 Foreign Films \n by Country")+
theme(axis.title.y = element_blank()) +
scale_x_continuous(trans='log10')
get_sentiments()
get_sentiments("afinn")
library(tidytext)
install.packages(tidytext)
library(tidytext)
library(dplyr)
get_sentiments("afinn")
install.packages("RedditExtractoR")
libary(RedditExctractoR)
library(RedditExctractoR)
install.packages("RedditExtractoR")
library(RedditExctractoR)
library(RedditExtractoR)
redgeo <- get_reddit(subreddit = "geopolitics", page_threshold = 5, sort_by = "comments")
library(RedditExtractoR)
redgeo <- get_reddit(subreddit = "geopolitics", page_threshold = 5, sort_by = "comments")
getcontent <- get_reddit(
search_terms = "Tolkien",
page_threshold = 1,
cn_threshold = 2500
)
library(RedditExctractoR)
library(RedditExtractoR)
getcontent <- find_subreddits("ukraine")
getcontent
view(getcontent)
getcontent <- find_thread_urls( keywords = NA, sort_by = "top", subreddit = "geopolitics", period = "month" )
view(getcontent)
getcontent <- find_thread_urls(keywords="ukraine", subreddit="geopolitics", sort_by="comment", period="month")
getcontent <- find_thread_urls(keywords="ukraine", subreddit="geopolitics", sort_by="new", period="month")
view(getcontent)
url <- ("https://www.reddit.com/r/geopolitics/")
getcontent <- get_thread_content(url)
view(getcontent)
getcontent <- get_thread_content(https://www.reddit.com/r/geopolitics/comments/t020va/russia_invasion_of_ukraine_live_thread/)
getcontent <- get_thread_content("https://www.reddit.com/r/geopolitics/comments/t020va/russia_invasion_of_ukraine_live_thread/")
view(getcontent)
library(SentimentAnalysis)
install.packages("SentimentAnalysis")
library(SentimentAnalysis)
names(getcontent)
getcontent$comments
view(getcontent$comments)
view(getcontent$threads)
getcontent <- get_thread_content("https://www.reddit.com/r/geopolitics/")
view(getcontent)
getcontent <- get_thread_content("https://www.reddit.com/r/geopolitics/")
getcontent <- get_thread_content("https://www.reddit.com/r/geopolitics/")
getcontent <- get_thread_content("https://www.reddit.com/r/geopolitics/comments/t020va/russia_invasion_of_ukraine_live_thread/")
view(getcontent$comments)
content <- getcontent$comments
graph <- construct_graph(content, plot = TRUE)
view(content)
graph <- construct_graph(content, plot = TRUE)
user <- user_network(content, include_author = TRUE, agg = TRUE)
sentiment <- analyzeSentiment(content$comment)
sentiment$sentimentQDAP
sentiment$SentimentQDAP
sentiment <- analyzeSentiment(content$comment)
sentiment$SentimentQDAP
library(SentimentAnalysis)
content <- getcontent$comments
sentiment <- analyzeSentiment(content$comment)
install.packages('sentimentr')
sentiment_by("I am having a good one", by = NULL)
sentiment("I am having a good one")
library(sentimentr)
sentiment("I am having a good one")
sentiment(content$comment)
sent <- sentiment(content$comment)
sent <- sentiment(content$comment)
view(sent)
view(sent)
content <- as.tibble(getcontent$comments)
content <- as_tibble(getcontent$comments)
content
content <- as_tibble(getcontent$comments)
head(content)
dim(content)
dim(content)
head(content)
head(sent)
view(sent)
ggplot(data = sent) +
geom_histogram(mapping = aes(x=sentiment))
sent %>%
filter(word_count > 1) -> sent
ggplot(data = sent) +
geom_histogram(mapping = aes(x=sentiment))
view(sent)
sent %>%
filter(word_count > 1) -> sent  #We are excluding words of length = 1 because these represents deleted comments.
ggplot(data = sent) +
geom_histogram(mapping = aes(x=sentiment))
sent %>%
filter(word_count > 3) -> sent  #We are excluding words of length = 1 because these represents short and irrelevant responses.
ggplot(data = sent) +
geom_histogram(mapping = aes(x=sentiment))
sent %>%
filter(word_count > 3) -> sent  #We are excluding words of length = 1 because these represents short and irrelevant responses.
# Example: Thank you, very true, deleted(when a comment is deleted), etc.
ggplot(data = sent) +
geom_histogram(mapping = aes(x=sentiment))+
labs(y = "Count", x = "Sentiment", title = "Histogram of Sentiment Scores")
# Example: Thank you, very true, deleted(when a comment is deleted), etc.
ggplot(data = sent) +
geom_histogram(mapping = aes(x=sentiment), color = "blue")+
labs(y = "Count", x = "Sentiment", title = "Histogram of Sentiment Scores")
# Example: Thank you, very true, deleted(when a comment is deleted), etc.
ggplot(data = sent) +
geom_histogram(mapping = aes(x=sentiment), color = "blue", fill = "gray")+
labs(y = "Count", x = "Sentiment", title = "Histogram of Sentiment Scores")
summary(sent)
ggplot(data = sent) +
geom_point(mapping = aes(x = word_count, y = sentiment))
ggplot(data = sent) +
geom_point(mapping = aes(x = word_count, y = sentiment)) +
geom_smooth(method = lm,se=F,aes(group=1),color='blue')
ggplot(data = sent) +
geom_point(mapping = aes(x = word_count, y = sentiment)) +
geom_smooth()
ggplot(data = sent) +
geom_point(mapping = aes(x = word_count, y = sentiment))
ggplot(data = sent) +
geom_point(mapping = aes(x = word_count, y = sentiment)) +
labs(y = "Sentiment Scores" y = "Length of Words per Sentence")
ggplot(data = sent) +
geom_point(mapping = aes(x = word_count, y = sentiment)) +
labs(y = "Sentiment Scores", y = "Length of Words per Sentence")
ggplot(data = sent) +
geom_point(mapping = aes(x = word_count, y = sentiment)) +
labs(y = "Sentiment Scores", x = "Length of Words per Sentence")
lm1 <- lm(sent$sentiment ~ sent$word_count)
summary(lm1)
ggplot(data = sent) +
geom_point(mapping = aes(x = word_count, y = sentiment)) +
labs(y = "Sentiment Scores", x = "Length of Words per Sentence", title = "Sentiment Scores vs Word Count")
knitr::opts_chunk$set(echo       = params$solutions,
eval       = params$solutions,
fig.align  = "center",
fig.height = 3,
fig.width  = 5)
sout <- summary(lm(mpg ~ wt, data = mtcars))
class(bsout)
class(sout)
bsout <- splines::bs(x = mtcars$wt, df = 10)
class(bsout)
typeof(sout)
attributes(sout)
attributes(sout)
sloop::s3_methods_class("summary.lm")
sloop::otype(lmout)
sloop::ftype(lmout)
sloop::otype(lmout)
sloop::ftype(lmout)
lmout <- lm(mpg ~ wt + am, data = mtcars)
library(sloop)
sloop::otype(lmout)
sloop::ftype(lmout)
class(lmout)
typeof(lmout)
bslm <- function(x, y, B = 1000, alpha = 0.05) {
lminit <- lm(y ~ x)
yhat <- fitted(lminit)
rvec <- resid(lminit)
b0vec <- rep(NA_real_, length.out = B)
b1vec <- rep(NA_real_, length.out = B)
for (i in seq_len(B)) {
ynew <- yhat + sample(rvec, replace = TRUE)
lmnew <- lm(ynew ~ x)
b0vec[[i]] <- coef(lmnew)[[1]]
b1vec[[i]] <- coef(lmnew)[[2]]
}
retlist <- list(
b0 = quantile(x = b0vec, probs = c(alpha / 2, 1 - alpha/2)),
b1 = quantile(x = b1vec, probs = c(alpha / 2, 1 - alpha/2))
)
return(retlist)
}
bslm(x = mtcars$wt, y = mtcars$mpg, B = 10000)
bslm.names()
names.bslm()
bslm <- function(x, y, B = 1000, alpha = 0.05) {
lminit <- lm(y ~ x)
yhat <- fitted(lminit)
rvec <- resid(lminit)
b0vec <- rep(NA_real_, length.out = B)
b1vec <- rep(NA_real_, length.out = B)
for (i in seq_len(B)) {
ynew <- yhat + sample(rvec, replace = TRUE)
lmnew <- lm(ynew ~ x)
b0vec[[i]] <- coef(lmnew)[[1]]
b1vec[[i]] <- coef(lmnew)[[2]]
}
retlist <- list(
b0 = quantile(x = b0vec, probs = c(alpha / 2, 1 - alpha/2)),
b1 = quantile(x = b1vec, probs = c(alpha / 2, 1 - alpha/2))
)
return(retlist)
}
names.bslm()
sloop::otype(lmout)
sloop::ftype(lmout)
typeof(lmout)
attributes(lmout)
attributes(bslm)
typeof(bslm)
bslm(x = mtcars$wt, y = mtcars$mpg, B = 10000)
bslm$b0
bslm['b0']
class(lmout)
sloop::otype(lmout)
typeof(bslm)
class(bslm)
sloop::otype(bslm)
shiny::runApp('D:/hw05-dbernal1/dc_energy')
runApp('D:/hw05-dbernal1/dc_energy')
energy
runApp('D:/hw05-dbernal1/dc_energy')
energy
# Transforming the data
df <- read_rds("~/data/energy_year.rds")
energy <- df %>%
mutate(Era =  case_when(Built < 1900 ~ "Pre-1900",
Built < 1951 ~ "Early-Mid 20th",
Built < 2000 ~ "Late 20th",
Built < 2011 ~ "Aughts",
Built > 2010 ~ "Teens and later")) %>%
mutate(Era = replace_na(Era, "Teens and later")) %>%
mutate(Report_Year = factor(Report_Year),
Type_SS = factor(Type_SS),
Type_EPA = factor(Type_EPA),
Metered_Energy = factor(Metered_Energy),
Metered_Water = factor(Metered_Water),
Era = factor(Era))
energy
runApp('D:/hw05-dbernal1/dc_energy')
typeof(energy$Report_Year)
# Transforming the data
df <- read_rds("~/data/energy_year.rds")
energy <- df %>%
mutate(Era =  case_when(Built < 1900 ~ "Pre-1900",
Built < 1951 ~ "Early-Mid 20th",
Built < 2000 ~ "Late 20th",
Built < 2011 ~ "Aughts",
Built > 2010 ~ "Teens and later")) %>%
mutate(Era = replace_na(Era, "Teens and later")) %>%
col_types = cols("Report_Year" = col_factor(),
"Type_SS" = col_factor(),
"Type_EPA" = col_factor(),
"Metered_Energy" = col_factor(),
"Metered_Water" = col_factor(),
"Era" = col_factor())
energy <- df %>%
mutate(Era =  case_when(Built < 1900 ~ "Pre-1900",
Built < 1951 ~ "Early-Mid 20th",
Built < 2000 ~ "Late 20th",
Built < 2011 ~ "Aughts",
Built > 2010 ~ "Teens and later"))
energy <- df %>%
mutate(Era =  case_when(Built < 1900 ~ "Pre-1900",
Built < 1951 ~ "Early-Mid 20th",
Built < 2000 ~ "Late 20th",
Built < 2011 ~ "Aughts",
Built > 2010 ~ "Teens and later")) %<%
mutate(Era = replace_na(Era, "Teens and later"))
energy <- df %>%
mutate(Era =  case_when(Built < 1900 ~ "Pre-1900",
Built < 1951 ~ "Early-Mid 20th",
Built < 2000 ~ "Late 20th",
Built < 2011 ~ "Aughts",
Built > 2010 ~ "Teens and later")) %>%
mutate(Era = replace_na(Era, "Teens and later"))
energy <- df %>%
mutate(Era =  case_when(Built < 1900 ~ "Pre-1900",
Built < 1951 ~ "Early-Mid 20th",
Built < 2000 ~ "Late 20th",
Built < 2011 ~ "Aughts",
Built > 2010 ~ "Teens and later")) %>%
mutate(Era = replace_na(Era, "Teens and later")) %>%
col_types = cols("Report_Year" = col_factor(),
"Type_SS" = col_factor(),
"Type_EPA" = col_factor(),
"Metered_Energy" = col_factor(),
"Metered_Water" = col_factor(),
"Era" = col_factor())
energy
energy <- df %>%
mutate(Era =  case_when(Built < 1900 ~ "Pre-1900",
Built < 1951 ~ "Early-Mid 20th",
Built < 2000 ~ "Late 20th",
Built < 2011 ~ "Aughts",
Built > 2010 ~ "Teens and later")) %>%
mutate(Era = replace_na(Era, "Teens and later"))
energy
energy <- col_types = cols("Report_Year" = col_factor(),
"Type_SS" = col_factor(),
"Type_EPA" = col_factor(),
"Metered_Energy" = col_factor(),
"Metered_Water" = col_factor(),
"Era" = col_factor())
# Transforming the data
df <- read_rds("~/data/energy_year.rds")
energy <- df %>%
mutate(Era =  case_when(Built < 1900 ~ "Pre-1900",
Built < 1951 ~ "Early-Mid 20th",
Built < 2000 ~ "Late 20th",
Built < 2011 ~ "Aughts",
Built > 2010 ~ "Teens and later")) %>%
mutate(Era = replace_na(Era, "Teens and later"))
energy <- (col_types = cols("Report_Year" = col_factor(),
"Type_SS" = col_factor(),
"Type_EPA" = col_factor(),
"Metered_Energy" = col_factor(),
"Metered_Water" = col_factor(),
"Era" = col_factor()))
energy
# Transforming the data
df <- read_rds("~/data/energy_year.rds")
energy <- df %>%
mutate(Era =  case_when(Built < 1900 ~ "Pre-1900",
Built < 1951 ~ "Early-Mid 20th",
Built < 2000 ~ "Late 20th",
Built < 2011 ~ "Aughts",
Built > 2010 ~ "Teens and later")) %>%
mutate(Era = replace_na(Era, "Teens and later")) %>%
mutate(Report_Year = factor(Report_Year),
Type_SS = factor(Type_SS),
Type_EPA = factor(Type_EPA),
Metered_Energy = factor(Metered_Energy),
Metered_Water = factor(Metered_Water),
Era = factor(Era))
energy
col_types(energy)
class(energy)
sapply(energy, typeof)
runApp('D:/hw05-dbernal1/dc_energy')
runApp('D:/hw05-dbernal1/dc_energy')
runApp('D:/hw05-dbernal1/dc_energy')
runApp('D:/hw05-dbernal1/dc_energy')
setwd("D:/Regression")
install.packages("leaps")
library(leaps)
setwd("")
HOMES = read.csv("HOME_SALES.csv")
attach(HOMES)
#install.packages("leaps")
library(leaps)
setwd("")
HOMES = read.csv("HOME_SALES.csv")
a
#install.packages("leaps")
library(leaps)
setwd("")
HOMES = read.csv("HOME_SALES.csv")
attach(HOMES)
reg.models = regsubsets( SALES_PRICE ~ FINISHED_AREA + BEDROOMS +   BATHROOMS + GARAGE_SIZE + YEAR_BUILT + as.factor(STYLE) + LOT_SIZE +  AIR_CONDITIONER + POOL + QUALITY + HIGHWAY, data=HOMES )
summary(reg.models)
summary(reg.models)$adjr2
summary(reg.models)$cp
summary(reg.models)$bic
summary(reg.models)$adjr2
summary(reg.models)$cp
summary(reg.models)$bic
which.max(summary(reg.models)$adjr2)
which.max(summary(reg.models)$cp)
which.max(summary(reg.models)$adjr2)
which.max(summary(reg.models)$bic)
which.max(summary(reg.models)$adjr2)
which.min(summary(reg.models)$cp)
which.min(summary(reg.models)$bic)
reg.backward = regsubsets( SALES_PRICE ~ FINISHED_AREA + BEDROOMS +  + BATHROOMS + GARAGE_SIZE + YEAR_BUILT + as.factor(STYLE) + LOT_SIZE + + AIR_CONDITIONER + POOL + QUALITY + HIGHWAY, data=HOMES, method = "backward")
reg.forward = regsubsets( SALES_PRICE ~ FINISHED_AREA + BEDROOMS +  + BATHROOMS + GARAGE_SIZE + YEAR_BUILT + as.factor(STYLE) + LOT_SIZE + + AIR_CONDITIONER + POOL + QUALITY + HIGHWAY, data=HOMES, method = "forward")
plot(reg.backward, scale = "adjr2" )
plot(reg.backward, scale = "cp" )
plot(reg.backward, scale = "Cp" )
plot(reg.backward, scale = "bic")
reg.null = lm( SALES_PRICE ~ 1,data=HOMES)
reg.full =lm( SALES_PRICE ~ . - ID - STYLE + as.factor(STYLE), data=HOMES)
step( reg.null, scope=list( lower=reg.null, upper=reg.full ), direction="forward")
step( reg.full, scope=list( lower=reg.null, upper=reg.full ), direction="backward" )
step(reg.null, scope=list(lower=reg.null, upper=reg.full), direction="both")
n = length(SALES_PRICE)
n
testing = sample(n,100)
testing
training = -testing
reg = lm( SALES_PRICE ~ . - ID - STYLE + as.factor(STYLE), data=HOMES, subset=training)
Yhat = predict(reg,HOMES)
length(Yhat)
MSPE = mean((SALES_PRICE[testing] - Yhat[testing])^2)
MSPE
reg1 = lm( SALES_PRICE ~ . - ID - STYLE, data=HOMES, subset=training )
Yhat = predict(reg1,HOMES)
MSPE = mean((SALES_PRICE[testing] - Yhat[testing])^2)
MSPE
par(mfrow=c(6,6))
plot(HOMES[c(2,3,4,5,7,9)])
520*.20
knitr::opts_chunk$set(echo = TRUE)
local({
hook_output <- knitr::knit_hooks$get('output')
knitr::knit_hooks$set(output = function(x, options) {
if (!is.null(options$max.height)) options$attr.output <- c(
options$attr.output,
sprintf('style="max-height: %s;"', options$max.height)
)
hook_output(x, options)
})
}) # to make output scrollable
library(keyring)
library(httr)
library(tidyverse)
library(tidytext)
install.packages("tidytext")
library(tidytext)
library(janeaustenr)
austen_books() %>%
unnest_tokens(word, text) %>%
mutate(word = str_extract(word, "[a-z']+")) %>%
count(book, word, sort = TRUE) ->
book_words
book_words %>%
group_by(book) %>%
summarize(total = sum(n), .groups = "drop") ->
total_words
book_words %>%
left_join(total_words, by = "book") ->
book_words
book_words
book_words %>%
ggplot(aes(n / total, fill = book)) +
geom_histogram(show.legend = FALSE) +
xlim(NA, 0.0009) +
facet_wrap(~ book, ncol = 2, scales = "free_y")
book_words %>%
filter(n == 1) %>%
nrow()
book_words %>%
group_by(book) %>%
mutate(rank = row_number(),
term_frequency =  n / total) ->
freq_by_rank
head(freq_by_rank, 10)
freq_by_rank %>%
ggplot(aes(rank, term_frequency, color = book)) +
geom_line(size = 1.1, alpha = 0.8, show.legend = FALSE) +
scale_x_log10() +
scale_y_log10()
knitr::opts_chunk$set(echo       = params$solutions,
eval       = params$solutions,
fig.align  = "center",
fig.height = 3,
fig.width  = 5)
libraries <- function(...) {
dots <- eval(substitute(alist(...)))
return(invisible(lapply(dots, function(x)
library(deparse(x), character.only=TRUE))))
}
libraries(broom, car)
isNamespaceLoaded("broom")
isNamespaceLoaded("car")
x <- c("diplry", "dani")
x <- c("diplry", "dani")
dots <- eval(substitute(alist(x)))
dots1 <- rlang::enexprs(x)
dots
dots1
x <- c("diplry", "dani")
dots <- eval(substitute(alist(x)))
dots1 <- eval(rlang::enexprs(x))
dots
dots1
libraries <- function(...) {
dots1 <- eval(rlang::enexprs(...))
return(invisible(lapply(dots, function(x)
library(deparse(x), character.only=TRUE))))
}
libraries(dplyr)
libraries <- function(...) {
dots <- eval(substitute(alist(...)))
return(invisible(lapply(dots, function(x)
library(deparse(x), character.only=TRUE))))
}
r
r
libraries(dplyr)
isNamespaceLoaded("dplyr")
setwd("D:/datascience/gp-004-ypd-crime/data")
data1 <- readRDS("leo2.other.RDS")
view(data1)
cor(data1$county_pop, data1$male_pop)
cor(data1$county_pop, data1$male_pop)
corr(data1$county_pop, data1$male_pop)
data$county_pop
data1$county_pop
